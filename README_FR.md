<div align="center">
    <h1> <img src="docs/images/logo.png" height=33 align="texttop"> OmAgent</h1>
</div>

<p align="center">
  <img src="docs/images/icon.png" width="300"/>
</p>

<p align="center">
  <a href="https://twitter.com/intent/follow?screen_name=OmAI_lab" target="_blank">
    <img alt="X (formerly Twitter) Follow" src="https://img.shields.io/twitter/follow/OmAI_lab">
  </a>
  <a href="https://discord.gg/9JfTJ7bk" target="_blank">
    <img alt="Discord" src="https://img.shields.io/discord/1296666215548321822?style=flat&logo=discord">
  </a>
</p>

<p align="center">
    <a href="README.md">English</a> | <a href="README_ZH.md">‰∏≠Êñá</a> | <a href="README_JP.md">Êó•Êú¨Ë™û</a> | <a>Fran√ßais</a>
</p>

---

## üóìÔ∏è Mises √† jour r√©centes
* **20/10/2024** : Nous nous engageons activement √† d√©velopper la v0.2.0 üöß De nouvelles fonctionnalit√©s passionnantes sont en cours ! Vous √™tes invit√©s √† nous rejoindre sur X et Discord~
* **20/09/2024** : Notre article a √©t√© accept√© par EMNLP 2024 ! Rejoignez-nous √† Miami ! üèù
* **04/07/2024** : Le projet open-source OmAgent est officiellement lanc√© ! üéâ
* **24/06/2024** : [Publication de l'article de recherche OmAgent](https://arxiv.org/abs/2406.16620).

---

## üìñ Introduction

OmAgent est un syst√®me intelligent et multimodal avanc√©, con√ßu pour exploiter la puissance des grands mod√®les de langage multimodal et d'algorithmes innovants afin d'accomplir des t√¢ches complexes. Le projet OmAgent comprend un cadre l√©ger, **omagent_core**, d√©velopp√© pour relever les d√©fis li√©s au multimodal. Il est adaptable √† vos propres id√©es et cas d'usage !

Les trois principaux composants d'OmAgent sont :  
- **Video2RAG** : Transforme la compr√©hension de longues vid√©os en une t√¢che RAG multimodale, avec l'avantage de d√©passer les limitations li√©es √† la longueur des vid√©os. Attention toutefois √† la perte potentielle de d√©tails durant le pr√©traitement.
- **DnCLoop** : Inspir√© par la m√©thode algorithmique ¬´ Diviser pour R√©gner ¬ª, ce module permet une approche it√©rative de r√©solution de probl√®mes complexes, en d√©composant chaque t√¢che jusqu'√† ce qu'elle soit facile √† r√©soudre.
- **Rewinder** : Con√ßu pour pallier la perte de d√©tails induite par le pr√©traitement dans Video2RAG, Rewinder permet aux agents de revisiter des moments cl√©s des vid√©os pour recueillir des informations suppl√©mentaires.

<p align="center">
  <img src="docs/images/OmAgent.png" width="700"/>
</p>

Pour plus d'informations, consultez notre article : **[OmAgent : Un cadre d'agent multimodal pour la compr√©hension vid√©o complexe avec Diviser pour R√©gner](https://arxiv.org/abs/2406.16620)**.

---

## üõ†Ô∏è Installation

### Pr√©requis

- Python ‚â• 3.10
- Installation de `omagent_core` :
  ```bash
  cd omagent-core
  pip install -e .
  ```

- Installation des autres d√©pendances :
  ```bash
  cd ..
  pip install -r requirements.txt
  ```

### üöÄ D√©marrage rapide

#### Traitement des t√¢ches g√©n√©rales

1. Cr√©ez un fichier de configuration `config.yaml` et d√©finissez les variables requises :
   ```bash
   cd workflows/general
   vim config.yaml
   ```

   | Nom de la configuration   | Utilisation                                                                                       |
   |---------------------------|---------------------------------------------------------------------------------------------------|
   | custom_openai_endpoint     | API pour OpenAI GPT ou un autre mod√®le, format : `{custom_openai_endpoint}/chat/completions`       |
   | custom_openai_key          | Cl√© API fournie par le fournisseur du mod√®le de langage                                            |
   | bing_api_key               | Cl√© API de Bing pour la recherche Web                                                              |

2. Configurez `run.py` pour ex√©cuter l'agent :
   ```python
   def run_agent(task):
       logging.init_logger("omagent", "omagent", level="INFO")
       registry.import_module(project_root=Path(__file__).parent, custom=["./engine"])
       bot_builder = Builder.from_file("workflows/general")
       input = DnCInterface(bot_id="1", task=AgentTask(id=0, task=task))
   
       bot_builder.run_bot(input)
       return input.last_output
   
   if __name__ == "__main__":
       run_agent("Votre requ√™te ici")
   ```

3. D√©marrez OmAgent en ex√©cutant :
   ```bash
   python run.py
   ```

---

## üß† T√¢che de compr√©hension vid√©o

### Pr√©paration de l'environnement

- **Optionnel** : Par d√©faut, OmAgent utilise Milvus Lite comme base de donn√©es vectorielle pour stocker les donn√©es. Vous pouvez d√©ployer la version compl√®te via Docker si n√©cessaire :
  ```bash
  curl -sfL https://raw.githubusercontent.com/milvus-io/milvus/master/scripts/standalone_embed.sh -o standalone_embed.sh
  bash standalone_embed.sh start
  ```

- **Optionnel** : Algorithme de reconnaissance faciale. Vous pouvez d√©sactiver cette fonctionnalit√© dans `video_tools.json` si elle n'est pas n√©cessaire.
  
  Si vous activez cette option, la base de donn√©es des visages est situ√©e dans `data/face_db`.

- **Optionnel** : Int√©gration d'OmDet pour la d√©tection d'objets dans les vid√©os.
  
  1. Installez OmDet depuis son [d√©p√¥t](https://github.com/om-ai-lab/OmDet).
  2. Exposez l'inf√©rence en tant qu'API via FastAPI :
     ```python
     pip install pydantic fastapi uvicorn
     ```

---

## üîó Travaux associ√©s
- [√âvaluation de la d√©tection de vocabulaire ouvert](https://arxiv.org/abs/2308.13177)  
- [OmDet: Pr√©-entra√Ænement multimodal pour la vision](https://ietresearch.onlinelibrary.wiley.com/doi/full/10.1049/cvi2.12268)

## ‚≠êÔ∏è Citation

Si ce projet vous est utile, veuillez citer notre article :
```bibtex
@article{zhang2024omagent,
  title={OmAgent: A Multi-modal Agent Framework for Complex Video Understanding with Task Divide-and-Conquer},
  author={Zhang, Lu et al.},
  journal={arXiv preprint arXiv:2406.16620},
  year={2024}
}
```
